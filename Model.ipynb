{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8582f78d",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "#### What type of model should we use?\n",
    "We wanted to determine which type of model. Because of the format of our data, we wanted to run the model season-by-season, using encoded vectors for the contestants. We will have to use a neural network to make a decision between the contestants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6532b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce23fb",
   "metadata": {},
   "source": [
    "# Part 1: Importing and formatting data for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0799577c",
   "metadata": {},
   "source": [
    "### We want the data in this format:\n",
    "\n",
    "Season #\n",
    "\n",
    "|tweets # (index) | character 1 mentioned | character 2 mentioned | ... | character n mentioned | sentiment analysis positive | sentiment analysis negative | sentiment analysis neutral | sentiment analysis compound| result|\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| int | bin | bin | bin | bin | float | float | float | float | Binary vector with len(n)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0484aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling in final datasets and deleting index columns\n",
    "master_data = pd.read_csv(\"./wikipedia_master.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "twitter_data = pd.read_csv(\"./twitter_data.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "# Changing twitter_data seasons to int from float\n",
    "twitter_data[\"Season\"] = twitter_data[\"Season\"].values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07db6ce3",
   "metadata": {},
   "source": [
    "#### Checking the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e01e077",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Season</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sentiment Analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BYE MARTIN I HOPE THE DOOR HITS YOU ON THE WAY...</td>\n",
       "      <td>18</td>\n",
       "      <td>11/30/21</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.791, 'pos': 0.209, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wow just getting caught up on  and man Michell...</td>\n",
       "      <td>18</td>\n",
       "      <td>11/30/21</td>\n",
       "      <td>{'neg': 0.083, 'neu': 0.564, 'pos': 0.353, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>11/30/21</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yo fuck Martin toxic ass bitch</td>\n",
       "      <td>18</td>\n",
       "      <td>11/30/21</td>\n",
       "      <td>{'neg': 0.783, 'neu': 0.217, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Martin walked so Chris S Could run</td>\n",
       "      <td>18</td>\n",
       "      <td>11/30/21</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6324</th>\n",
       "      <td>WAIT WAIT MEDICAL MALPRACTICE DEFENSE ATTORNEY...</td>\n",
       "      <td>16</td>\n",
       "      <td>11/16/20</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.791, 'pos': 0.209, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6325</th>\n",
       "      <td>Taysha Is Pretty</td>\n",
       "      <td>16</td>\n",
       "      <td>11/16/20</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.385, 'pos': 0.615, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6326</th>\n",
       "      <td>Kaitlyn Bristowe Shows Off DWTS Injuries Tv Sh...</td>\n",
       "      <td>16</td>\n",
       "      <td>11/16/20</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6327</th>\n",
       "      <td>Love a good Wells cameo</td>\n",
       "      <td>16</td>\n",
       "      <td>11/16/20</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.099, 'pos': 0.901, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6328</th>\n",
       "      <td>WAIT is she not joining us for  tomorrow</td>\n",
       "      <td>16</td>\n",
       "      <td>11/16/20</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6329 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Season      Date  \\\n",
       "0     BYE MARTIN I HOPE THE DOOR HITS YOU ON THE WAY...      18  11/30/21   \n",
       "1     Wow just getting caught up on  and man Michell...      18  11/30/21   \n",
       "2                                                   NaN      18  11/30/21   \n",
       "3                        yo fuck Martin toxic ass bitch      18  11/30/21   \n",
       "4                   Martin walked so Chris S Could run       18  11/30/21   \n",
       "...                                                 ...     ...       ...   \n",
       "6324  WAIT WAIT MEDICAL MALPRACTICE DEFENSE ATTORNEY...      16  11/16/20   \n",
       "6325                                  Taysha Is Pretty       16  11/16/20   \n",
       "6326  Kaitlyn Bristowe Shows Off DWTS Injuries Tv Sh...      16  11/16/20   \n",
       "6327                           Love a good Wells cameo       16  11/16/20   \n",
       "6328           WAIT is she not joining us for  tomorrow      16  11/16/20   \n",
       "\n",
       "                                     Sentiment Analysis  \n",
       "0     {'neg': 0.0, 'neu': 0.791, 'pos': 0.209, 'comp...  \n",
       "1     {'neg': 0.083, 'neu': 0.564, 'pos': 0.353, 'co...  \n",
       "2     {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...  \n",
       "3     {'neg': 0.783, 'neu': 0.217, 'pos': 0.0, 'comp...  \n",
       "4     {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "...                                                 ...  \n",
       "6324  {'neg': 0.0, 'neu': 0.791, 'pos': 0.209, 'comp...  \n",
       "6325  {'neg': 0.0, 'neu': 0.385, 'pos': 0.615, 'comp...  \n",
       "6326  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "6327  {'neg': 0.0, 'neu': 0.099, 'pos': 0.901, 'comp...  \n",
       "6328  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "\n",
       "[6329 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00263288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date Aired</th>\n",
       "      <th>Contestants</th>\n",
       "      <th>Voted Off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>5/27/13</td>\n",
       "      <td>['Chris Siegfried' 'Drew Kenney' 'Brooks Fores...</td>\n",
       "      <td>['Diogo Custodio', 'Larry Burchett', 'Micah He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>6/3/13</td>\n",
       "      <td>['Chris Siegfried' 'Drew Kenney' 'Brooks Fores...</td>\n",
       "      <td>['Nick Mucci', 'Robert Graham', 'Will Reese']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>6/10/13</td>\n",
       "      <td>['Chris Siegfried' 'Drew Kenney' 'Brooks Fores...</td>\n",
       "      <td>['Brandon Andreen', 'Dan Cox', 'Brian Jarosins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>6/17/13</td>\n",
       "      <td>['Chris Siegfried' 'Drew Kenney' 'Brooks Fores...</td>\n",
       "      <td>['Zack Kalter', 'Brad McKinzie']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>Week 5</td>\n",
       "      <td>6/24/13</td>\n",
       "      <td>['Chris Siegfried' 'Drew Kenney' 'Brooks Fores...</td>\n",
       "      <td>['Mikey Tenerelli', 'Ben Scott', 'Bryden Vukas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>11/9/21</td>\n",
       "      <td>['Brandon Jones' 'Joe Coleman' 'Nayte Olukoya'...</td>\n",
       "      <td>['Chris Gallant', 'Romeo Alexander', 'Will Ure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>Week 5</td>\n",
       "      <td>11/16/21</td>\n",
       "      <td>['Brandon Jones' 'Joe Coleman' 'Nayte Olukoya'...</td>\n",
       "      <td>['Casey Woods', 'Leroy Arthur', 'Chris Sutton']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>Week 6</td>\n",
       "      <td>11/23/21</td>\n",
       "      <td>['Brandon Jones' 'Joe Coleman' 'Nayte Olukoya'...</td>\n",
       "      <td>['Olumide \"Olu\" Onajide', 'Rick Leach', 'Marti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>Week 7</td>\n",
       "      <td>11/30/21</td>\n",
       "      <td>['Brandon Jones' 'Joe Coleman' 'Nayte Olukoya'...</td>\n",
       "      <td>['Rodney Matthews']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>Week 8</td>\n",
       "      <td>12/14/21</td>\n",
       "      <td>['Brandon Jones' 'Joe Coleman' 'Nayte Olukoya'...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Season  Episode   Title Date Aired  \\\n",
       "0        9        1  Week 1    5/27/13   \n",
       "1        9        2  Week 2     6/3/13   \n",
       "2        9        3  Week 3    6/10/13   \n",
       "3        9        4  Week 4    6/17/13   \n",
       "4        9        5  Week 5    6/24/13   \n",
       "..     ...      ...     ...        ...   \n",
       "95      18        4  Week 4    11/9/21   \n",
       "96      18        5  Week 5   11/16/21   \n",
       "97      18        6  Week 6   11/23/21   \n",
       "98      18        7  Week 7   11/30/21   \n",
       "99      18        9  Week 8   12/14/21   \n",
       "\n",
       "                                          Contestants  \\\n",
       "0   ['Chris Siegfried' 'Drew Kenney' 'Brooks Fores...   \n",
       "1   ['Chris Siegfried' 'Drew Kenney' 'Brooks Fores...   \n",
       "2   ['Chris Siegfried' 'Drew Kenney' 'Brooks Fores...   \n",
       "3   ['Chris Siegfried' 'Drew Kenney' 'Brooks Fores...   \n",
       "4   ['Chris Siegfried' 'Drew Kenney' 'Brooks Fores...   \n",
       "..                                                ...   \n",
       "95  ['Brandon Jones' 'Joe Coleman' 'Nayte Olukoya'...   \n",
       "96  ['Brandon Jones' 'Joe Coleman' 'Nayte Olukoya'...   \n",
       "97  ['Brandon Jones' 'Joe Coleman' 'Nayte Olukoya'...   \n",
       "98  ['Brandon Jones' 'Joe Coleman' 'Nayte Olukoya'...   \n",
       "99  ['Brandon Jones' 'Joe Coleman' 'Nayte Olukoya'...   \n",
       "\n",
       "                                            Voted Off  \n",
       "0   ['Diogo Custodio', 'Larry Burchett', 'Micah He...  \n",
       "1       ['Nick Mucci', 'Robert Graham', 'Will Reese']  \n",
       "2   ['Brandon Andreen', 'Dan Cox', 'Brian Jarosins...  \n",
       "3                    ['Zack Kalter', 'Brad McKinzie']  \n",
       "4   ['Mikey Tenerelli', 'Ben Scott', 'Bryden Vukas...  \n",
       "..                                                ...  \n",
       "95  ['Chris Gallant', 'Romeo Alexander', 'Will Ure...  \n",
       "96    ['Casey Woods', 'Leroy Arthur', 'Chris Sutton']  \n",
       "97  ['Olumide \"Olu\" Onajide', 'Rick Leach', 'Marti...  \n",
       "98                                ['Rodney Matthews']  \n",
       "99                                                 []  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e3d69d",
   "metadata": {},
   "source": [
    "#### We need to clean the data I imported from permanent, .csv storage as dtypes were not preserved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a12f1927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wikipedia Data Parsing\n",
    "\n",
    "dates = master_data[\"Date Aired\"]\n",
    "dates_new = []\n",
    "conts = master_data[\"Contestants\"]\n",
    "conts_new = []\n",
    "vo = master_data[\"Voted Off\"]\n",
    "vo_new = []\n",
    "\n",
    "# Getting dates back into datetime format\n",
    "for i in range(len(dates)):\n",
    "    dates_new.append(datetime.strptime(dates[i], \"%m/%d/%y\"))\n",
    "    \n",
    "# getting the list of contestants as a list\n",
    "for i in range(len(conts)):\n",
    "    temp_conts = conts[i][2:-2]\n",
    "    temp_conts = temp_conts.replace(\"\\n\", \"\")\n",
    "    temp_conts = temp_conts.split(\"' '\")\n",
    "    conts_new.append(temp_conts)\n",
    "    \n",
    "# getting list of voted off as a list\n",
    "for i in range(len(vo)):\n",
    "    temp_vo = vo[i][2:-2]\n",
    "\n",
    "    temp_vo = temp_vo.replace(\"\\n\", \"\")\n",
    "    temp_vo = temp_vo.split(\"', '\")\n",
    "    if temp_vo == ['']:\n",
    "        temp_vo = [\"0\"]\n",
    "    vo_new.append(temp_vo)\n",
    " \n",
    "\n",
    "data = {\"Date Aired\": dates_new, \"Contestants\": conts_new, \"Voted Off\": vo_new}\n",
    "\n",
    "master_data.drop(columns=[\"Date Aired\", \"Contestants\", \"Voted Off\"], inplace=True)\n",
    "\n",
    "master_data = master_data.join(pd.DataFrame(data=data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d891b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter Data Parsing\n",
    "\n",
    "dates = twitter_data[\"Date\"]\n",
    "dates_new = []\n",
    "scores = twitter_data[\"Sentiment Analysis\"]\n",
    "scores_new = []\n",
    "\n",
    "# Getting dates back into datetime format\n",
    "for i in range(len(dates)):\n",
    "    dates_new.append(datetime.strptime(dates[i], \"%m/%d/%y\"))\n",
    "    \n",
    "# getting the sentiment analysis scores as a dictionary\n",
    "for i in range(len(scores)):\n",
    "    sc = scores[i][1:-1].split(\", \")\n",
    "    temp_dict = {\"neg\": None, \"neu\": None, \"pos\": None, \"compound\": None}\n",
    "    temp_list = []\n",
    "    for entry in sc:\n",
    "        score = float(entry.split(\": \")[1])\n",
    "        temp_list.append(score)\n",
    "    temp_dict[\"neg\"] = temp_list[0]\n",
    "    temp_dict[\"neu\"] = temp_list[1]\n",
    "    temp_dict[\"pos\"] = temp_list[2]\n",
    "    temp_dict[\"compound\"] = temp_list[3]\n",
    "    scores_new.append(temp_dict)\n",
    "\n",
    "# Creating a new dictionary with the data extracted in the correct datatype    \n",
    "data = {\"Date\": dates_new, \"Sentiment Analysis\": scores_new}\n",
    "\n",
    "# Dropping the columns to replace from the current dataframe\n",
    "twitter_data.drop(columns=[\"Date\", \"Sentiment Analysis\"], inplace=True)\n",
    "\n",
    "# Adding the new data in place of the old data\n",
    "twitter_data = twitter_data.join(pd.DataFrame(data=data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d361fba1",
   "metadata": {},
   "source": [
    "#### We have to now extract all the data we need which we will put into a dictionary of dataframes with each dataframe having the model-ready data for each season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22425ea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Establishing a useful dictionary to be used for the rest of the code\n",
    "all_data = {9:None, 10:None, 11:None, 12:None, 13:None,  \n",
    "        14:None, 15:None, 16:None, 18:None}\n",
    "\n",
    "tweets_per_season = []\n",
    "\n",
    "# For each season\n",
    "for season in all_data.keys():\n",
    "    \n",
    "    # Get subsets of the dataframes and establish a season dictionary\n",
    "    season_data = defaultdict()\n",
    "    twitter_subset = twitter_data[twitter_data[\"Season\"] == season]\n",
    "    wikipedia_subset = master_data[master_data[\"Season\"] == season]\n",
    "\n",
    "    # for each tweet that happened that season\n",
    "    for i in range(len(twitter_subset)):\n",
    "        episode_data = defaultdict()\n",
    "        \n",
    "        # Get the sentiment analysis scores and add them to the season dictionary\n",
    "        episode_data[\"Positive Scores\"] = twitter_subset.iat[i, 3][\"pos\"]\n",
    "        episode_data[\"Neutral Scores\"] = twitter_subset.iat[i, 3][\"neu\"]\n",
    "        episode_data[\"Negative Scores\"] = twitter_subset.iat[i, 3][\"neg\"]\n",
    "        episode_data[\"Compound Scores\"] = twitter_subset.iat[i, 3][\"compound\"]\n",
    "        \n",
    "        # extract the date of the tweet\n",
    "        tweet_date = twitter_subset.iat[i, 2]\n",
    "        \n",
    "        # initialize an episode_date variable for use in comparing tweet date with the episode date\n",
    "        episode_date = None\n",
    "        \n",
    "        # If it was live tweeted, then use the date of the tweet as the episode date\n",
    "        for date in wikipedia_subset[\"Date Aired\"]:\n",
    "            if tweet_date == date:\n",
    "                episode_date = tweet_date\n",
    "                break\n",
    "            else:\n",
    "                # if it was not live tweeted, step back a few days until the nearest episode and use that episode\n",
    "                for d in range(7):\n",
    "                    td = timedelta(days=d)\n",
    "                    date_forward = date + td\n",
    "                    if tweet_date == date_forward:\n",
    "                        episode_date = date\n",
    "\n",
    "        # get who was voted off for that tweet, along with some gross formatting fixes           \n",
    "        voted_off = list(wikipedia_subset[wikipedia_subset[\"Date Aired\"] == episode_date][\"Voted Off\"])\n",
    "        if voted_off == []:\n",
    "            voted_off = [[\"0\"]]\n",
    "        voted_off = voted_off[0]\n",
    "        \n",
    "        # establish the value n which will define the number of extra columns for the encoded-vectors of the contestants\n",
    "        contestants = wikipedia_subset.iat[0, 4]\n",
    "        n = len(contestants)\n",
    "        \n",
    "        # getting a list of first names of the contestants for crossreferencing with tweet mentions\n",
    "        contestants_first_names = set([name.split(\" \")[0].lower() for name in contestants])\n",
    "        \n",
    "        # extracting the text of the tweets as a list of words\n",
    "        tweet_text_split = str(twitter_subset.iat[i, 0]).split(\" \")\n",
    "        tweet_text_split = set([word.lower() for word in tweet_text_split])\n",
    "        \n",
    "        # extracting the mentions of characters from the tweets\n",
    "        mentions = tweet_text_split.intersection(contestants_first_names)\n",
    "        \n",
    "        # creating vectors for mentions with length n (number of characters)\n",
    "        for name in contestants_first_names:\n",
    "            if name in mentions:\n",
    "                episode_data[name] = 1\n",
    "            else:\n",
    "                episode_data[name] = 0\n",
    "                \n",
    "        # creating the softmax vector for y-data in the model\n",
    "        vec = []\n",
    "        for name in contestants:\n",
    "            if name in voted_off:\n",
    "                vec.append(1)\n",
    "            else:\n",
    "                vec.append(0)\n",
    "        \n",
    "        # adding the final vector to the episode_data dictionary\n",
    "        episode_data[\"Voted Off\"] = vec\n",
    "\n",
    "        # if this is the first tweet, add the keys of episode_data to the season_data and make them lists\n",
    "        # if not, append the values from that episode to  season_data lists\n",
    "        if i == 0:\n",
    "            for key in episode_data.keys():\n",
    "                season_data[key] = []\n",
    "        else:\n",
    "            for key in episode_data.keys():\n",
    "                season_data[key].append(episode_data[key])\n",
    "    \n",
    "    # Using season_data, create a Dataframe and add it to the all_data dictionary\n",
    "    all_data[season] = pd.DataFrame(data=season_data)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f027a305",
   "metadata": {},
   "source": [
    "### Now we have a dictionary of DataFrames which are formatted correctly for a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "217e5dfa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive Scores</th>\n",
       "      <th>Neutral Scores</th>\n",
       "      <th>Negative Scores</th>\n",
       "      <th>Compound Scores</th>\n",
       "      <th>brad</th>\n",
       "      <th>michael</th>\n",
       "      <th>juan</th>\n",
       "      <th>zak</th>\n",
       "      <th>brooks</th>\n",
       "      <th>kasey</th>\n",
       "      <th>...</th>\n",
       "      <th>jonathan</th>\n",
       "      <th>larry</th>\n",
       "      <th>brian</th>\n",
       "      <th>will</th>\n",
       "      <th>nick</th>\n",
       "      <th>zack</th>\n",
       "      <th>mikey</th>\n",
       "      <th>bryden</th>\n",
       "      <th>mike</th>\n",
       "      <th>Voted Off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.314</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.425</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.326</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Positive Scores  Neutral Scores  Negative Scores  Compound Scores  brad  \\\n",
       "0            0.000           1.000              0.0           0.0000     0   \n",
       "1            0.000           1.000              0.0           0.0000     0   \n",
       "2            0.314           0.686              0.0           0.4939     0   \n",
       "3            0.425           0.575              0.0           0.5709     0   \n",
       "4            0.326           0.674              0.0           0.4404     0   \n",
       "\n",
       "   michael  juan  zak  brooks  kasey  ...  jonathan  larry  brian  will  nick  \\\n",
       "0        0     1    0       0      0  ...         0      0      0     0     0   \n",
       "1        0     0    0       0      0  ...         0      0      0     0     0   \n",
       "2        0     0    0       0      0  ...         0      0      0     0     0   \n",
       "3        0     0    0       0      0  ...         0      0      0     0     0   \n",
       "4        0     0    0       0      0  ...         0      0      0     0     0   \n",
       "\n",
       "   zack  mikey  bryden  mike  \\\n",
       "0     0      0       0     0   \n",
       "1     0      0       0     0   \n",
       "2     0      0       0     0   \n",
       "3     0      0       0     0   \n",
       "4     0      0       0     0   \n",
       "\n",
       "                                           Voted Off  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking that the data is in the format we want!\n",
    "all_data[9].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f56dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data to .csv files\n",
    "for key in all_data.keys():\n",
    "    all_data[key].to_csv(\"./model_data/season_%i_model_data.csv\"%key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf565ac",
   "metadata": {},
   "source": [
    "# Part 2: Model development\n",
    "\n",
    "#### We wanted to use a basic 20-neuron, three layer neural network using keras to predict a length-n output vector which can be mapped to contestant names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2cd9bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "# Creating a function which returns the model of the correct architecture and dimensions\n",
    "def make_model(n_cols, n_contestants):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=n_cols, activation = 'relu'))\n",
    "    model.add(Dense(20, activation = 'relu'))\n",
    "    model.add(Dense(n_contestants, activation='softmax'))\n",
    "    \n",
    "    # Optimize with stochastic gradient descent, with the loss function as mean squared error\n",
    "    model.compile(optimizer='sgd',\n",
    "                  loss='mse',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cce28bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Season 9\n",
      "Epoch 1/25\n",
      "107/107 [==============================] - 0s 872us/step - loss: 0.0798 - accuracy: 0.0150\n",
      "Epoch 2/25\n",
      "107/107 [==============================] - 0s 772us/step - loss: 0.0798 - accuracy: 0.0169\n",
      "Epoch 3/25\n",
      "107/107 [==============================] - 0s 724us/step - loss: 0.0798 - accuracy: 0.0169\n",
      "Epoch 4/25\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.0169\n",
      "Epoch 5/25\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.0169\n",
      "Epoch 6/25\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.0178\n",
      "Epoch 7/25\n",
      "107/107 [==============================] - 0s 886us/step - loss: 0.0797 - accuracy: 0.0178\n",
      "Epoch 8/25\n",
      "107/107 [==============================] - 0s 660us/step - loss: 0.0797 - accuracy: 0.0169\n",
      "Epoch 9/25\n",
      "107/107 [==============================] - 0s 704us/step - loss: 0.0797 - accuracy: 0.0160\n",
      "Epoch 10/25\n",
      "107/107 [==============================] - 0s 743us/step - loss: 0.0797 - accuracy: 0.0160\n",
      "Epoch 11/25\n",
      "107/107 [==============================] - 0s 724us/step - loss: 0.0797 - accuracy: 0.0160\n",
      "Epoch 12/25\n",
      "107/107 [==============================] - 0s 891us/step - loss: 0.0797 - accuracy: 0.0160\n",
      "Epoch 13/25\n",
      "107/107 [==============================] - 0s 757us/step - loss: 0.0797 - accuracy: 0.0160\n",
      "Epoch 14/25\n",
      "107/107 [==============================] - 0s 658us/step - loss: 0.0797 - accuracy: 0.0160\n",
      "Epoch 15/25\n",
      "107/107 [==============================] - 0s 711us/step - loss: 0.0797 - accuracy: 0.0160\n",
      "Epoch 16/25\n",
      "107/107 [==============================] - 0s 885us/step - loss: 0.0797 - accuracy: 0.0169\n",
      "Epoch 17/25\n",
      "107/107 [==============================] - 0s 827us/step - loss: 0.0797 - accuracy: 0.0178\n",
      "Epoch 18/25\n",
      "107/107 [==============================] - 0s 844us/step - loss: 0.0797 - accuracy: 0.0178\n",
      "Epoch 19/25\n",
      "107/107 [==============================] - 0s 828us/step - loss: 0.0797 - accuracy: 0.0178\n",
      "Epoch 20/25\n",
      "107/107 [==============================] - 0s 687us/step - loss: 0.0797 - accuracy: 0.0178\n",
      "Epoch 21/25\n",
      "107/107 [==============================] - 0s 717us/step - loss: 0.0797 - accuracy: 0.0178\n",
      "Epoch 22/25\n",
      "107/107 [==============================] - 0s 753us/step - loss: 0.0797 - accuracy: 0.0178\n",
      "Epoch 23/25\n",
      "107/107 [==============================] - 0s 683us/step - loss: 0.0797 - accuracy: 0.0188\n",
      "Epoch 24/25\n",
      "107/107 [==============================] - 0s 669us/step - loss: 0.0797 - accuracy: 0.0197\n",
      "Epoch 25/25\n",
      "107/107 [==============================] - 0s 705us/step - loss: 0.0797 - accuracy: 0.0197\n",
      "34/34 [==============================] - 0s 612us/step - loss: 0.0797 - accuracy: 0.0197\n",
      "\n",
      "Season 10\n",
      "Epoch 1/25\n",
      "71/71 [==============================] - 0s 712us/step - loss: 0.0733 - accuracy: 0.0382\n",
      "Epoch 2/25\n",
      "71/71 [==============================] - 0s 971us/step - loss: 0.0733 - accuracy: 0.0382\n",
      "Epoch 3/25\n",
      "71/71 [==============================] - 0s 881us/step - loss: 0.0733 - accuracy: 0.0382\n",
      "Epoch 4/25\n",
      "71/71 [==============================] - 0s 871us/step - loss: 0.0733 - accuracy: 0.0396\n",
      "Epoch 5/25\n",
      "71/71 [==============================] - 0s 899us/step - loss: 0.0733 - accuracy: 0.0396\n",
      "Epoch 6/25\n",
      "71/71 [==============================] - 0s 847us/step - loss: 0.0733 - accuracy: 0.0396\n",
      "Epoch 7/25\n",
      "71/71 [==============================] - 0s 846us/step - loss: 0.0733 - accuracy: 0.0396\n",
      "Epoch 8/25\n",
      "71/71 [==============================] - 0s 673us/step - loss: 0.0733 - accuracy: 0.0396\n",
      "Epoch 9/25\n",
      "71/71 [==============================] - 0s 833us/step - loss: 0.0733 - accuracy: 0.0396\n",
      "Epoch 10/25\n",
      "71/71 [==============================] - 0s 826us/step - loss: 0.0733 - accuracy: 0.0396\n",
      "Epoch 11/25\n",
      "71/71 [==============================] - 0s 737us/step - loss: 0.0732 - accuracy: 0.0396\n",
      "Epoch 12/25\n",
      "71/71 [==============================] - 0s 709us/step - loss: 0.0732 - accuracy: 0.0396\n",
      "Epoch 13/25\n",
      "71/71 [==============================] - 0s 690us/step - loss: 0.0732 - accuracy: 0.0396\n",
      "Epoch 14/25\n",
      "71/71 [==============================] - 0s 714us/step - loss: 0.0732 - accuracy: 0.0396\n",
      "Epoch 15/25\n",
      "71/71 [==============================] - 0s 705us/step - loss: 0.0732 - accuracy: 0.0396\n",
      "Epoch 16/25\n",
      "71/71 [==============================] - 0s 674us/step - loss: 0.0732 - accuracy: 0.0396\n",
      "Epoch 17/25\n",
      "71/71 [==============================] - 0s 758us/step - loss: 0.0732 - accuracy: 0.0396\n",
      "Epoch 18/25\n",
      "71/71 [==============================] - 0s 767us/step - loss: 0.0732 - accuracy: 0.0396\n",
      "Epoch 19/25\n",
      "71/71 [==============================] - 0s 678us/step - loss: 0.0732 - accuracy: 0.0396\n",
      "Epoch 20/25\n",
      "71/71 [==============================] - 0s 680us/step - loss: 0.0732 - accuracy: 0.0396\n",
      "Epoch 21/25\n",
      "71/71 [==============================] - 0s 775us/step - loss: 0.0732 - accuracy: 0.0396\n",
      "Epoch 22/25\n",
      "71/71 [==============================] - 0s 793us/step - loss: 0.0732 - accuracy: 0.0396\n",
      "Epoch 23/25\n",
      "71/71 [==============================] - 0s 876us/step - loss: 0.0732 - accuracy: 0.0396\n",
      "Epoch 24/25\n",
      "71/71 [==============================] - 0s 751us/step - loss: 0.0732 - accuracy: 0.0396\n",
      "Epoch 25/25\n",
      "71/71 [==============================] - 0s 688us/step - loss: 0.0732 - accuracy: 0.0396\n",
      "23/23 [==============================] - 0s 564us/step - loss: 0.0732 - accuracy: 0.0396\n",
      "\n",
      "Season 11\n",
      "Epoch 1/25\n",
      "91/91 [==============================] - 0s 700us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 2/25\n",
      "91/91 [==============================] - 0s 630us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 3/25\n",
      "91/91 [==============================] - 0s 822us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 4/25\n",
      "91/91 [==============================] - 0s 659us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 5/25\n",
      "91/91 [==============================] - 0s 698us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 6/25\n",
      "91/91 [==============================] - 0s 716us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 7/25\n",
      "91/91 [==============================] - 0s 685us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 8/25\n",
      "91/91 [==============================] - 0s 699us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 9/25\n",
      "91/91 [==============================] - 0s 736us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 10/25\n",
      "91/91 [==============================] - 0s 816us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 11/25\n",
      "91/91 [==============================] - 0s 720us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 12/25\n",
      "91/91 [==============================] - 0s 774us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 13/25\n",
      "91/91 [==============================] - 0s 698us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 14/25\n",
      "91/91 [==============================] - 0s 728us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 15/25\n",
      "91/91 [==============================] - 0s 687us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 16/25\n",
      "91/91 [==============================] - 0s 708us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 17/25\n",
      "91/91 [==============================] - 0s 718us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 18/25\n",
      "91/91 [==============================] - 0s 721us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 19/25\n",
      "91/91 [==============================] - 0s 707us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 20/25\n",
      "91/91 [==============================] - 0s 630us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 21/25\n",
      "91/91 [==============================] - 0s 653us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 22/25\n",
      "91/91 [==============================] - 0s 740us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 23/25\n",
      "91/91 [==============================] - 0s 761us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 24/25\n",
      "91/91 [==============================] - 0s 720us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "Epoch 25/25\n",
      "91/91 [==============================] - 0s 739us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "29/29 [==============================] - 0s 676us/step - loss: 0.0856 - accuracy: 0.0044\n",
      "\n",
      "Season 12\n",
      "Epoch 1/25\n",
      "52/52 [==============================] - 0s 810us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 2/25\n",
      "52/52 [==============================] - 0s 729us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 829us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 4/25\n",
      "52/52 [==============================] - 0s 755us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 5/25\n",
      "52/52 [==============================] - 0s 757us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 6/25\n",
      "52/52 [==============================] - 0s 682us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 7/25\n",
      "52/52 [==============================] - 0s 644us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 8/25\n",
      "52/52 [==============================] - 0s 672us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 9/25\n",
      "52/52 [==============================] - 0s 663us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 10/25\n",
      "52/52 [==============================] - 0s 704us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 11/25\n",
      "52/52 [==============================] - 0s 704us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 12/25\n",
      "52/52 [==============================] - 0s 709us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 13/25\n",
      "52/52 [==============================] - 0s 784us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 14/25\n",
      "52/52 [==============================] - 0s 885us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 15/25\n",
      "52/52 [==============================] - 0s 681us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 16/25\n",
      "52/52 [==============================] - 0s 746us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 17/25\n",
      "52/52 [==============================] - 0s 793us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 18/25\n",
      "52/52 [==============================] - 0s 756us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 19/25\n",
      "52/52 [==============================] - 0s 630us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 20/25\n",
      "52/52 [==============================] - 0s 692us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 21/25\n",
      "52/52 [==============================] - 0s 646us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 22/25\n",
      "52/52 [==============================] - 0s 633us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 23/25\n",
      "52/52 [==============================] - 0s 631us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 24/25\n",
      "52/52 [==============================] - 0s 650us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "Epoch 25/25\n",
      "52/52 [==============================] - 0s 679us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "17/17 [==============================] - 0s 692us/step - loss: 0.0786 - accuracy: 0.0848\n",
      "\n",
      "Season 13\n",
      "Epoch 1/25\n",
      "49/49 [==============================] - 0s 822us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 2/25\n",
      "49/49 [==============================] - 0s 701us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 3/25\n",
      "49/49 [==============================] - 0s 765us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 4/25\n",
      "49/49 [==============================] - 0s 726us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 5/25\n",
      "49/49 [==============================] - 0s 713us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 6/25\n",
      "49/49 [==============================] - 0s 689us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 7/25\n",
      "49/49 [==============================] - 0s 677us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 8/25\n",
      "49/49 [==============================] - 0s 749us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 9/25\n",
      "49/49 [==============================] - 0s 703us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 10/25\n",
      "49/49 [==============================] - 0s 704us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 11/25\n",
      "49/49 [==============================] - 0s 693us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 12/25\n",
      "49/49 [==============================] - 0s 659us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 13/25\n",
      "49/49 [==============================] - 0s 677us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 14/25\n",
      "49/49 [==============================] - 0s 737us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 15/25\n",
      "49/49 [==============================] - 0s 727us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 16/25\n",
      "49/49 [==============================] - 0s 736us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 17/25\n",
      "49/49 [==============================] - 0s 830us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 18/25\n",
      "49/49 [==============================] - 0s 748us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 19/25\n",
      "49/49 [==============================] - 0s 773us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 20/25\n",
      "49/49 [==============================] - 0s 762us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 21/25\n",
      "49/49 [==============================] - 0s 730us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 22/25\n",
      "49/49 [==============================] - 0s 727us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 23/25\n",
      "49/49 [==============================] - 0s 749us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 24/25\n",
      "49/49 [==============================] - 0s 715us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "Epoch 25/25\n",
      "49/49 [==============================] - 0s 721us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "16/16 [==============================] - 0s 787us/step - loss: 0.0807 - accuracy: 0.0514\n",
      "\n",
      "Season 14\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 0s 709us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 0s 849us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 0s 770us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 0s 930us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 0s 833us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 0s 751us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 0s 827us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 0s 792us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 0s 815us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 0s 714us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 0s 863us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 0s 808us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 0s 729us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 0s 754us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 0s 793us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 0s 766us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 0s 754us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 0s 675us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 0s 803us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 0s 710us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 0s 733us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 0s 676us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 0s 757us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 0s 657us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 0s 661us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "16/16 [==============================] - 0s 754us/step - loss: 0.0751 - accuracy: 0.0863\n",
      "\n",
      "Season 15\n",
      "Epoch 1/25\n",
      "40/40 [==============================] - 0s 791us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 2/25\n",
      "40/40 [==============================] - 0s 712us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 3/25\n",
      "40/40 [==============================] - 0s 792us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 4/25\n",
      "40/40 [==============================] - 0s 869us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 5/25\n",
      "40/40 [==============================] - 0s 693us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 858us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 7/25\n",
      "40/40 [==============================] - 0s 874us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 8/25\n",
      "40/40 [==============================] - 0s 804us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 9/25\n",
      "40/40 [==============================] - 0s 752us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 10/25\n",
      "40/40 [==============================] - 0s 799us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 11/25\n",
      "40/40 [==============================] - 0s 703us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 12/25\n",
      "40/40 [==============================] - 0s 840us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 13/25\n",
      "40/40 [==============================] - 0s 720us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 14/25\n",
      "40/40 [==============================] - 0s 703us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 15/25\n",
      "40/40 [==============================] - 0s 673us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 16/25\n",
      "40/40 [==============================] - 0s 741us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 17/25\n",
      "40/40 [==============================] - 0s 696us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 18/25\n",
      "40/40 [==============================] - 0s 688us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 19/25\n",
      "40/40 [==============================] - 0s 685us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 20/25\n",
      "40/40 [==============================] - 0s 686us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 21/25\n",
      "40/40 [==============================] - 0s 667us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 22/25\n",
      "40/40 [==============================] - 0s 682us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 23/25\n",
      "40/40 [==============================] - 0s 694us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 24/25\n",
      "40/40 [==============================] - 0s 675us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "Epoch 25/25\n",
      "40/40 [==============================] - 0s 646us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 715us/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
      "\n",
      "Season 16\n",
      "Epoch 1/25\n",
      "171/171 [==============================] - 0s 573us/step - loss: 0.1069 - accuracy: 0.0000e+00\n",
      "Epoch 2/25\n",
      "171/171 [==============================] - 0s 615us/step - loss: 0.1068 - accuracy: 0.0000e+00\n",
      "Epoch 3/25\n",
      "171/171 [==============================] - 0s 625us/step - loss: 0.1068 - accuracy: 0.0000e+00\n",
      "Epoch 4/25\n",
      "171/171 [==============================] - 0s 615us/step - loss: 0.1068 - accuracy: 0.0000e+00\n",
      "Epoch 5/25\n",
      "171/171 [==============================] - 0s 615us/step - loss: 0.1068 - accuracy: 0.0000e+00\n",
      "Epoch 6/25\n",
      "171/171 [==============================] - 0s 606us/step - loss: 0.1068 - accuracy: 0.0000e+00\n",
      "Epoch 7/25\n",
      "171/171 [==============================] - 0s 586us/step - loss: 0.1068 - accuracy: 0.0000e+00\n",
      "Epoch 8/25\n",
      "171/171 [==============================] - 0s 576us/step - loss: 0.1068 - accuracy: 0.0000e+00\n",
      "Epoch 9/25\n",
      "171/171 [==============================] - 0s 584us/step - loss: 0.1068 - accuracy: 0.0000e+00\n",
      "Epoch 10/25\n",
      "171/171 [==============================] - 0s 579us/step - loss: 0.1067 - accuracy: 0.0000e+00\n",
      "Epoch 11/25\n",
      "171/171 [==============================] - 0s 617us/step - loss: 0.1067 - accuracy: 0.0000e+00\n",
      "Epoch 12/25\n",
      "171/171 [==============================] - 0s 698us/step - loss: 0.1067 - accuracy: 0.0000e+00\n",
      "Epoch 13/25\n",
      "171/171 [==============================] - 0s 743us/step - loss: 0.1067 - accuracy: 0.0000e+00\n",
      "Epoch 14/25\n",
      "171/171 [==============================] - 0s 626us/step - loss: 0.1067 - accuracy: 0.0000e+00\n",
      "Epoch 15/25\n",
      "171/171 [==============================] - 0s 554us/step - loss: 0.1067 - accuracy: 0.0152\n",
      "Epoch 16/25\n",
      "171/171 [==============================] - 0s 773us/step - loss: 0.1067 - accuracy: 0.0269\n",
      "Epoch 17/25\n",
      "171/171 [==============================] - 0s 850us/step - loss: 0.1067 - accuracy: 0.0450\n",
      "Epoch 18/25\n",
      "171/171 [==============================] - 0s 829us/step - loss: 0.1067 - accuracy: 0.0789\n",
      "Epoch 19/25\n",
      "171/171 [==============================] - 0s 661us/step - loss: 0.1066 - accuracy: 0.1292\n",
      "Epoch 20/25\n",
      "171/171 [==============================] - 0s 710us/step - loss: 0.1066 - accuracy: 0.1292\n",
      "Epoch 21/25\n",
      "171/171 [==============================] - 0s 848us/step - loss: 0.1066 - accuracy: 0.1292\n",
      "Epoch 22/25\n",
      "171/171 [==============================] - 0s 902us/step - loss: 0.1066 - accuracy: 0.1292\n",
      "Epoch 23/25\n",
      "171/171 [==============================] - 0s 865us/step - loss: 0.1066 - accuracy: 0.1292\n",
      "Epoch 24/25\n",
      "171/171 [==============================] - 0s 776us/step - loss: 0.1066 - accuracy: 0.1292\n",
      "Epoch 25/25\n",
      "171/171 [==============================] - 0s 817us/step - loss: 0.1066 - accuracy: 0.1292\n",
      "54/54 [==============================] - 0s 625us/step - loss: 0.1066 - accuracy: 0.1292\n",
      "\n",
      "Season 18\n",
      "Epoch 1/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 2/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 3/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 4/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 5/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 6/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 7/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 8/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 9/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 10/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 11/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 12/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 13/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 14/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 15/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 16/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 17/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 18/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 19/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 20/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 21/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 22/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 23/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 24/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 25/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.data import Dataset\n",
    "\n",
    "# season list for iteratively running the model and an accuracy list for permanently storing model accuracies\n",
    "seasons = [9, 10, 11, 12, 13, 14, 15, 16, 18]\n",
    "accuracy = []\n",
    "\n",
    "for season in seasons:\n",
    "    # Useful variables for use in model creation\n",
    "    n_cols = len(all_data[season].columns)-1\n",
    "    n_contestants = len(all_data[season].iloc[0, -1])\n",
    "    \n",
    "    # set up datasets for training\n",
    "    x = tf.cast(all_data[season].iloc[:, :-1], tf.float32)                   # Casting all of the matrix data as a float\n",
    "    y = np.array([np.array(vec) for vec in all_data[season].iloc[:, -1]])    # Casting the target vector as a 2D vector of ndarrays\n",
    "\n",
    "    # create the model based on the season (i.e. number of columns and contestants)\n",
    "    model = make_model(n_cols, n_contestants)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Fitting the model to the season's data\n",
    "    print(\"\\nSeason %s\" % season)\n",
    "    model.fit(x, y, epochs=25, batch_size=10)\n",
    "    \n",
    "    # Getting training accuracy only from the modelÂ \n",
    "    # We did not have enough data to get both training and testing accuracies\n",
    "    scores = model.evaluate(x, y)\n",
    "    accuracy.append(scores[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3619815f",
   "metadata": {},
   "source": [
    "# Part 3: Model Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07ec7c1",
   "metadata": {},
   "source": [
    "#### Here is a description of the model architecture. Note: the final Dense layer's shape is dependent on how many contestants we have in the season. The model below represents Season 18, which had 30 contestants, and thus the model had a 30-Neuron, softmax output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1da02fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 20)                660       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 30)                630       \n",
      "=================================================================\n",
      "Total params: 1,710\n",
      "Trainable params: 1,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ca5417",
   "metadata": {},
   "source": [
    "#### Accuracies from the model:\n",
    "\n",
    "Below show the seasons and the accuracy of the models associated with the seasons. It is clear that, while our accuracies are not too high, the model does better than guessing, especially because the output layer ranged from 25-30 neurons, and the likelihood choosing the correct 1-3 people out of that large of a group is incredibly small.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bed471b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season 9 accuracy: 0.0197\n",
      "Season 10 accuracy: 0.0396\n",
      "Season 11 accuracy: 0.0044\n",
      "Season 12 accuracy: 0.0848\n",
      "Season 13 accuracy: 0.0514\n",
      "Season 14 accuracy: 0.0863\n",
      "Season 15 accuracy: 0.0000\n",
      "Season 16 accuracy: 0.1292\n",
      "Season 18 accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "for season, acc in zip(seasons, accuracy):\n",
    "    print(\"Season %.0i accuracy: %.04f\"% (season, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be6148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
